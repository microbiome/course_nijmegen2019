[
["index.html", "Introduction to microbiome data science 1 Introduction 1.1 Preparing for the course 1.2 Useful functions/resources 1.3 Focus 1.4 Target audience 1.5 Citation 1.6 License", " Introduction to microbiome data science Leo Lahti 2019-08-10 1 Introduction This course is organised in collaboration with Department of Mathematics and Statistics University of Turku, Finland. It will be held at Radboud University, Nijmegen on Sep 12-13, 2019. The course will cover the standard workflow in taxonomic profiling studies, with a focus on human gut microbiota, ranging from low-level preprocessing to statistical analysis, visualization, and reproducible reporting. 1.1 Preparing for the course We recommend using your own laptop. If this is not possible, kindly contact the organizers. Install the following software before the course: R Download link. Rstudio Download link. 1.2 Useful functions/resources Base R R Markdown RStudio IDE ggplot2 phyloseq microbiome R graphics cookbook List of R tools for microbiome analysis 1.3 Focus The primary aim is introduce microbial community data analysis. There will be talks and discussion on theory and methodology for analysis of microbial community data. We will cover topics ranging from design of studies, sequencing technologies, importance of controls and standardized DNA processing. Supervised hands-on training covering analyses from raw reads using NG-Tax, downstream analysis in R for exploration and analysis of microbiome sequencing data will be priority. There will be a strong focus on using R, R Studio for moving towards reproducible and open science. 1.4 Target audience Anyone who plans to or is currently doing high throughput microbial community analysis. 1.5 Citation If you found this useful, please cite: Lahti Leo, Henrik Eckerman, Sudarshan Shetty (2019). Introduction to microbiome data science. 1.6 License The 2-Clause BSD License "],
["course-overview.html", "2 Course overview 2.1 12 September: 2.2 13 September: 2.3 Material 2.4 Literature", " 2 Course overview Data exploration and analysis in gut microbiome profiling studies 2.1 12 September: Session 1 (9.30-11.30 / 2 hours) Overview of a standard bioinformatics workflow in microbiome research. - Ecosystem view of the gut microbiome: from bugs to communities and function - Preprocessing and quality control - Diagnostic plots and properties of microbiome data - Common methods: DADA2 (SVs) etc. - Analysis and modeling of taxonomic composition - Principal coordinates analysis &amp; other common visualization techniques - Differential abundance analysis - Varieties of alpha and beta diversity - Identification of community types (DMM) - Quantification of associations with external factors such as age, diet, or medication - Reproducible research and best practices in microbiome data science Session 2 (12-13 / 1 hour) KEYNOTE: Modern statistics in human gut microbiome research Overview of a standard bioinformatics workflow in microbiome research. Highlight how properties of microbiome data, such as sparsity, non-Gaussianity, and compositionality influences the choice and performance of the statistical methods: CLR; PCA vs. PCoA; community-level vs. subcommunity vs. species level; DESeq2; multiple testing; Role of reproducible research and best practices in microbiome data science Session 3 (14.30-17.30 / 3 hours including breaks) Hands-on session: introduction to R tools (microbiome, microbiomeutilities, phyloseq, other) 3A) Introduction to phyloseq &amp; example data (from 16S rRNA amplicon profiling studies) 3B) Generating a reproducible report with Rmarkdown 3C) Examples on microbiome data visualization and diversity analysis 2.2 13 September: Session 4 (9.30-12:00 / 2.5 hours) Lunch 12:00-13:30 (1.5 hours) Session 5 (13:30-15:00 / 1.5 hours) Downstream analysis and modeling of taxonomic composition within and between individuals or experimental groups Break (15:00-15:30 / 0.5 hours) Session 6 (15:30-17:00 / 1.5 hours) - Pointers to other tools &amp; environments (QIIME2, Anvi’o) - Wrap-up &amp; conclusions 2.3 Material https://datacarpentry.org/R-ecology-lesson/ 2.4 Literature Modern Statistics for Modern Biology. Holmes &amp; Huber (2018):. URL: http://web.stanford.edu/class/bios221/book/ Signatures of ecological processes in microbial community time series. Faust K et al. Microbiome, 6(120) 2018 Multi-stability and the origin of microbial community types. Faust et al. ISME Journal, 11:2159–2166, 2017. Linking statistical and ecological theory: Hubbell’s unified neutral theory of biodiversity as a hierarchical Dirichlet process. Harris et al. Proceedings of the IEEE, 105(3):516–529, 2017. Metagenomics meets time series analysis: unraveling microbial community dynamics. Faust K. Current Opinion in Microbiology, 25:56–66, 2015. Microbial communities as dynamical systems. Gonze D et al. Current Opinion in Microbiology, 44:41–49, 2018. Microbiome Data Science. Shetty &amp; Lahti, 2019. URL: https://openresearchlabs.github.io/publications/papers/2018-Shetty-Lahti-MDS.pdf "],
["set-up-and-pre-processing.html", "3 Set-up and Pre-processing 3.1 OTU or ASVs or sOTUs 3.2 General overview 3.3 Structure 3.4 Making a phyloseq object", " 3 Set-up and Pre-processing This tutorial will introduce you to basic steps of microbial community analysis. More importantly on how to look at your data and filter appropriately. We will use the Human microbiome project phase I data. 3.1 OTU or ASVs or sOTUs For past few years (maybe decade), identifying Operational taxonomic units (OTUs) from raw sequences used clustering approach. Using 97% identity cut-off was a standard approach and often closed reference OTU picking was accepted in the sicentific community. During the time of the development of tools and bioinformatics approaches this was possibly the best available method. However, as with many other fields of science, the knowledge has been updated. Evolution of bioinformatics approaches is a constant process. Based on current knowledge, the cons of 97% OTU picking stratergy (using clustering approaches) have out-weighed the pros (eg. less time). Recent approaches are now focused towards Amplicon Seuence Variants/sOTUs: * Oligotyping * Deblur * DADA2 * NG-Tax All above approaches have one common theme, they avoid 97% clustering and focus on minor differences (in many cases single nucleotide variations) to identify unique ASVs/sOTU. Note: Some how naming is different and variable. For this purpose and in this book, I will stick to ASVs when data from NG-tax is used. In this, section, we will compare outputs from 97% OTU picking approach and NG-tax approach. The data used here is the 16S rRNA gene variable region (V1-V3) for 97% OTU-pciking. The raw reads were processed using QIIME 1.9.1, SortMeRNA, and OTU picking was done using the closed-reference OTU-picking at 97% identity. For NG-Tax, we use the same raw data and processed through default settings. Here, we do not aim to bench mark. For this course, we aim to show differences between results from two approaches. For down stream analysis of *.biom files we use Phyloseq and microbiome. Kindly cite all the packages and tools that were used in your analysis as listed at the end of each document in sessionInfo. Also make sure that you provide the workflow and scripts you used for analysis atleast as supplementary material with your research article. Check Quick-R. 3.2 General overview 3.3 Structure Let us create few folders to organize the analysis. While this can be personal preference, make sure you write the structure to guide others who do not know your data well. # Create Folders as following # Tables dir.create(&quot;tables&quot;) # Figures dir.create(&quot;figures&quot;) # Phyloseq objects dir.create(&quot;phyobjects&quot;) # Custom codes/notes dir.create(&quot;codes_notes&quot;) Load packages library(microbiome) # data analysis and visualisation library(phyloseq) # also the basis of data object. Data analysis and visualisation library(microbiomeutilities) # some utility tools library(RColorBrewer) # nice color options library(ggpubr) # publication quality figures, based on ggplot2 library(DT) # interactive tables in html and markdown library(data.table) # alternative to data.frame library(dplyr) # data handling 3.4 Making a phyloseq object This is the basis for the analyses demonstrated in this tutorial. In the phyloseq object, information on OTU abundances, taxonomy of OTUs, the phylogenetic tree and metadata is stored. A single object with all this information provides a convinient way of handling, manipulating and visualizing data. For more infromation: phyloseq Please remember that the metadata (i.e. mapping) file has to be in .csv format (columns have sample attributes). The read_phylseq function from microbiome package requires metadata in .csv format. Things to be done in QIIME terminal (if required): Important Note 2: If you have error in loading the biom files stating JSON or HDF5 then you need to convert it in to a JSON format. For this, use the following command within the QIIME terminal and not in R! # biom convert -i NGTaxMerged.biom -o ngtax_json.biom --table-type &quot;OTU table&quot; --to-json For more information on the biom format please click here. Important Note 3: The most recent version of NG-Tax does not have this issue. NOTE The read_phyloseq function can be used for reading other outputs (like .shared and consensus taxonomy files from mothur) into phyloseq object. type ?read_phyloseq in the console pane for more information. If you don’t have your own biom file, we have a test dataset stored in input_data. Unzip the humanmicrobiome.zip and you will have the original biom file, copy it in the input_data folder. "]
]
