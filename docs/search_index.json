[
["index.html", "Introduction to microbiome data science 1 Introduction 1.1 Preparing for the course 1.2 Useful functions/resources 1.3 Focus 1.4 Target audience", " Introduction to microbiome data science Leo Lahti 2019-07-29 1 Introduction This course is organised in collaboration with Department of Mathematics and Statistics University of Turku, Finland. It will be held at Radboud University, Nijmegen on Sep 12-13, 2019. The course will cover the standard workflow in taxonomic profiling studies, with a focus on human gut microbiota, ranging from low-level preprocessing to statistical analysis, visualization, and reproducible reporting. 1.1 Preparing for the course We recommend using your own laptop. If this is not possible, kindly contact the organizers. Install the following software before the course: R Download link. Rstudio Download link. 1.2 Useful functions/resources Base R R Markdown RStudio IDE ggplot2 phyloseq microbiome R graphics cookbook List of R tools for microbiome analysis 1.3 Focus The primary aim is introduce microbial community data analysis. There will be talks and discussion on theory and methodology for analysis of microbial community data. We will cover topics ranging from design of studies, sequencing technologies, importance of controls and standardized DNA processing. Supervised hands-on training covering analyses from raw reads using NG-Tax, downstream analysis in R for exploration and analysis of microbiome sequencing data will be priority. There will be a strong focus on using R, R Studio for moving towards reproducible and open science. 1.4 Target audience Anyone who plans to or is currently doing high throughput microbial community analysis. "],
["citation.html", "2 Citation 2.1 License", " 2 Citation If you found this useful, please cite: Lahti Leo, Henrik Eckerman, Sudarshan Shetty (2019). Introduction to microbiome data science. 2.1 License The 2-Clause BSD License "],
["set-up-and-pre-processing.html", "3 Set-up and Pre-processing 3.1 OTU or ASVs or sOTUs 3.2 General overview 3.3 Structure 3.4 Making a phyloseq object", " 3 Set-up and Pre-processing This tutorial will introduce you to basic steps of microbial community analysis. More importantly on how to look at your data and filter appropriately. We will use the Human microbiome project phase I data. 3.1 OTU or ASVs or sOTUs For past few years (maybe decade), identifying Operational taxonomic units (OTUs) from raw sequences used clustering approach. Using 97% identity cut-off was a standard approach and often closed reference OTU picking was accepted in the sicentific community. During the time of the development of tools and bioinformatics approaches this was possibly the best available method. However, as with many other fields of science, the knowledge has been updated. Evolution of bioinformatics approaches is a constant process. Based on current knowledge, the cons of 97% OTU picking stratergy (using clustering approaches) have out-weighed the pros (eg. less time). Recent approaches are now focused towards Amplicon Seuence Variants/sOTUs: * Oligotyping * Deblur * DADA2 * NG-Tax All above approaches have one common theme, they avoid 97% clustering and focus on minor differences (in many cases single nucleotide variations) to identify unique ASVs/sOTU. Note: Some how naming is different and variable. For this purpose and in this book, I will stick to ASVs when data from NG-tax is used. In this, section, we will compare outputs from 97% OTU picking approach and NG-tax approach. The data used here is the 16S rRNA gene variable region (V1-V3) for 97% OTU-pciking. The raw reads were processed using QIIME 1.9.1, SortMeRNA, and OTU picking was done using the closed-reference OTU-picking at 97% identity. For NG-Tax, we use the same raw data and processed through default settings. Here, we do not aim to bench mark. For this course, we aim to show differences between results from two approaches. For down stream analysis of *.biom files we use Phyloseq and microbiome. Kindly cite all the packages and tools that were used in your analysis as listed at the end of each document in sessionInfo. Also make sure that you provide the workflow and scripts you used for analysis atleast as supplementary material with your research article. Check Quick-R. 3.2 General overview 3.3 Structure Let us create few folders to organize the analysis. While this can be personal preference, make sure you write the structure to guide others who do not know your data well. # Create Folders as following # Tables dir.create(&quot;tables&quot;) # Figures dir.create(&quot;figures&quot;) # Phyloseq objects dir.create(&quot;phyobjects&quot;) # Custom codes/notes dir.create(&quot;codes_notes&quot;) Load packages library(microbiome) # data analysis and visualisation library(phyloseq) # also the basis of data object. Data analysis and visualisation library(microbiomeutilities) # some utility tools library(RColorBrewer) # nice color options library(ggpubr) # publication quality figures, based on ggplot2 library(DT) # interactive tables in html and markdown library(data.table) # alternative to data.frame library(dplyr) # data handling 3.4 Making a phyloseq object This is the basis for the analyses demonstrated in this tutorial. In the phyloseq object, information on OTU abundances, taxonomy of OTUs, the phylogenetic tree and metadata is stored. A single object with all this information provides a convinient way of handling, manipulating and visualizing data. For more infromation: phyloseq Please remember that the metadata (i.e. mapping) file has to be in .csv format (columns have sample attributes). The read_phylseq function from microbiome package requires metadata in .csv format. Things to be done in QIIME terminal (if required): Important Note 2: If you have error in loading the biom files stating JSON or HDF5 then you need to convert it in to a JSON format. For this, use the following command within the QIIME terminal and not in R! # biom convert -i NGTaxMerged.biom -o ngtax_json.biom --table-type &quot;OTU table&quot; --to-json For more information on the biom format please click here. Important Note 3: The most recent version of NG-Tax does not have this issue. NOTE The read_phyloseq function can be used for reading other outputs (like .shared and consensus taxonomy files from mothur) into phyloseq object. type ?read_phyloseq in the console pane for more information. If you don’t have your own biom file, we have a test dataset stored in input_data. Unzip the humanmicrobiome.zip and you will have the original biom file, copy it in the input_data folder. "],
["differential-abundance-testing-for-univariate-data.html", "4 Differential abundance testing for univariate data 4.1 Load example data 4.2 Visual comparison of two groups 4.3 Statistical comparison of two groups 4.4 Investigate assumptions of the t-test 4.5 Compare results between parametric and non-parametric tests", " 4 Differential abundance testing for univariate data This section covers basic univariate tests for two-group comparison, covering t-test, Wilcoxon test, and multiple testing. You can try out the suggested exercises in the hands-on session. These are followed by example solutions which we will cover in more detail in the class. 4.1 Load example data The following example compares the abundance of a selected bug between two conditions. We assume that the data is already properly normalized. library(microbiome) theme_set(theme_bw(20)) data(dietswap) d &lt;- dietswap # Pick microbial abundances for a given taxonomic group taxa &lt;- &quot;Dialister&quot; # Construct a data.frame with the selected # taxonomic group and grouping df &lt;- data.frame(Abundance = abundances(d)[taxa,], Group = meta(d)$nationality) library(knitr) kable(head(df)) Abundance Group Sample-1 5 AAM Sample-2 23 AFR Sample-3 6 AFR Sample-4 24 AFR Sample-5 6 AFR Sample-6 38 AFR 4.2 Visual comparison of two groups Task: Compare the groups visually Tips: boxplot, density plot, histogram Visualization of the absolute abundances is shown on the left. Let us try the log10 transformation. Now, the data contains many zeros and taking log10 will yield infinite values. Hence we choose the commonly used, although somewhat problematic, log10(1+x) transformation (right). library(ggplot2) p1 &lt;- ggplot(df, aes(x = Group, y = Abundance)) + geom_boxplot() + labs(title = &quot;Absolute abundances&quot;, y = &quot;Abundance (read count)&quot;) # Let us add the log10(1+x) version: df$Log10_Abundance &lt;- log10(1 + df$Abundance) p2 &lt;- ggplot(df, aes(x = Group, y = Log10_Abundance)) + geom_boxplot() + labs(title = &quot;Log10 abundances&quot;, y = &quot;Abundance (log10(1+x) read count)&quot;) library(patchwork) p1 + p2 4.3 Statistical comparison of two groups Task: Test whether abundance differences are statistically significant between the two groups Tips: t-test (t.test); Wilcoxon test (wilcox.test). Find information on how to use by typing help(t.test) or help(wilcox.test); or by looking for examples from the web. The groups seem to differ. First, let us perform the t-test. This is based on Gaussian assumptions. Each group is expected to follow Gaussian distribution. Significance p-value with t-test: print(t.test(Log10_Abundance ~ Group, data = df)$p.value) ## [1] 0.02554997 According to this, the abundances is not significantly different between the two groups (at \\(p&lt;0.05\\) level). 4.4 Investigate assumptions of the t-test Task: Assess whether the abundance data is Gaussian or log-normal within each group You can use for instance histogram (hist) or density plots (plot(density())). Now let us investigate the Gaussian assumption of the t-test in more detail. Let us try another visualization; the density plot. p &lt;- ggplot(df, aes(fill = Group, x = Log10_Abundance)) + geom_density(alpha = 0.5) print(p) Apparently, the data is not even approximately Gaussian distributed. In such cases, a common procedure is to use non-parametric tests. These do not make assumptions of the data distribution but instead compare the ordering of the samples. So, let us look at the significance p-value with Wilcoxon test (log10 data): print(wilcox.test(Log10_Abundance ~ Group, data = df)$p.value) ## [1] 0.02979053 But since the test is non-parametric, we can as well use the original absolute abundances; thelog transformation does not change sample ordering on which the Wilcoxon test is based. Let us verify that the absolute abundances yield the same p-value for Wilcoxon test: print(wilcox.test(Abundance ~ Group, data = df)$p.value) ## [1] 0.02979053 4.5 Compare results between parametric and non-parametric tests Let us compare how much the results would differ in the whole data between t-test (parametric) and Wilcoxon test (non-parametric).To remove non-varying taxa that would demand extra scripting, let us for demonstration purposes now focus on core taxa that are observed in more than 20% of the samples with more than 3 reads. # Core taxa to be tested test.taxa &lt;- core_members(d, prevalence = 20/100, detection = 3) # Calculate p-values with the two different methods for each taxonomic unit pvalue.ttest &lt;- c() pvalue.wilcoxon &lt;- c() for (taxa in test.taxa) { # Create a new data frame for each taxonomic group df &lt;- data.frame(Abundance = abundances(d)[taxa,], Log10_Abundance = log10(1 + abundances(d)[taxa,]), Group = meta(d)$nationality) pvalue.ttest[[taxa]] &lt;- t.test(Log10_Abundance ~ Group, data = df)$p.value pvalue.wilcoxon[[taxa]] &lt;- wilcox.test(Abundance ~ Group, data = df)$p.value } # Arrange the results in a data.frame pvalues &lt;- data.frame(taxon = test.taxa, pvalue.ttest = pvalue.ttest, pvalue.wilcoxon = pvalue.wilcoxon) # Note that multiple testing occurs. # We must correct the p-values. # let us apply the standard Benjamini-Hochberg False Discovery Rate (FDR) # correction pvalues$pvalue.ttest.adjusted &lt;- p.adjust(pvalues$pvalue.ttest) pvalues$pvalue.wilcoxon.adjusted &lt;- p.adjust(pvalues$pvalue.wilcoxon) Compare the distribution of raw and adjusteed p-values. p1 &lt;- ggplot(pvalues, aes(x = pvalue.wilcoxon)) + geom_histogram() + labs(title = &quot;Raw p-values&quot;) + ylim(c(0, 80)) p2 &lt;- ggplot(pvalues, aes(x = pvalue.wilcoxon.adjusted)) + geom_histogram() + labs(title = &quot;Adjusted p-values&quot;) + ylim(c(0, 80)) print(p1 + p2) Now compare these adjusted p-values between t-test and Wilcoxon test. Let us also highlight the p = 0.05 intervals. p &lt;- ggplot(data = pvalues, aes(x = pvalue.ttest.adjusted, y = pvalue.wilcoxon.adjusted)) + geom_text(aes(label = taxon)) + geom_abline(aes(intercept = 0, slope = 1)) + geom_hline(aes(yintercept = 0.05), shape = 2) + geom_vline(aes(xintercept = 0.05), shape = 2) print(p) "],
["linear-models-the-role-of-covariates.html", "5 Linear models: the role of covariates 5.1 Fitting a linear model 5.2 Interpreting linear model output 5.3 Covariate testing", " 5 Linear models: the role of covariates This section provides hands-on introduction to linear (and generalized linear) models. Task Fit linear model to compare abundance between the two groups. You can use functions lm or glm, for instance. 5.1 Fitting a linear model Let us compare two groups with a linear model. We use Log10 abundances since this is closer to the Gaussian assumptions than the absolute count data. Fit a linear model with Gaussian variation as follows: res &lt;- glm(Log10_Abundance ~ Group, data = df, family = &quot;gaussian&quot;) 5.2 Interpreting linear model output Investigate the model coefficients: knitr::kable(summary(res)$coefficients, digits = 5) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 0.64825 0.02877 22.53405 0 GroupAFR 0.20313 0.04308 4.71530 0 The intercept equals to the mean in the first group: print(mean(subset(df, Group == &quot;AAM&quot;)$Log10_Abundance)) ## [1] 0.6482493 The group term equals to the difference between group means: print(mean(subset(df, Group == &quot;AFR&quot;)$Log10_Abundance) - mean(subset(df, Group == &quot;AAM&quot;)$Log10_Abundance)) ## [1] 0.2031287 Note that the linear model (default) significance equals to t-test assuming equal variances. print(t.test(Log10_Abundance ~ Group, data = df, var.equal=TRUE)$p.value) ## [1] 4.284318e-06 5.3 Covariate testing Task: Investigate how sex and bmi affect the results. An important advantage of linear and generalized linear models, compared to plain t-test is that they allow incorporating additional variables, such as potential confounders (age, BMI, gender..): # Add a covariate: df$sex &lt;- meta(d)$sex df$bmi_group &lt;- meta(d)$bmi_group # Fit the model: res &lt;- glm(Log10_Abundance ~ Group + sex + bmi_group, data = df, family = &quot;gaussian&quot;) We can even include interaction terms: res &lt;- glm(Log10_Abundance ~ Group * sex * bmi_group, data = df, family = &quot;gaussian&quot;) kable(coefficients(res)) x (Intercept) 0.8736029 GroupAFR 0.0261450 sexmale 0.0022871 bmi_groupoverweight -0.3160401 bmi_groupobese -0.2117135 GroupAFR:sexmale -0.2180267 GroupAFR:bmi_groupoverweight 0.5360971 GroupAFR:bmi_groupobese 0.2396655 sexmale:bmi_groupoverweight 0.0133203 sexmale:bmi_groupobese NA GroupAFR:sexmale:bmi_groupoverweight NA GroupAFR:sexmale:bmi_groupobese NA For more examples on using and analysing linear models, see statmethods regression and [ANOVA](See also statmethods tutorials. Try to adapt those examples on our microbiome example data data sets. "],
["advanced-models-for-differential-abundance.html", "6 Advanced models for differential abundance 6.1 Particular properties of taxonomic profiling data 6.2 Generalized linear models: a brief overview 6.3 DESeq2: differential abundance testing for sequencing data", " 6 Advanced models for differential abundance GLMs are the basis for advanced testing of differential abundance in sequencing data. This is necessary, as the sequencing data sets deviate from symmetric, continuous, Gaussian assumptions in many ways. 6.1 Particular properties of taxonomic profiling data 6.1.1 Discrete count data Sequencing data consists of discrete counts: print(abundances(d)[1:5,1:3]) ## Sample-1 Sample-2 Sample-3 ## Actinomycetaceae 0 1 0 ## Aerococcus 0 0 0 ## Aeromonas 0 0 0 ## Akkermansia 18 97 67 ## Alcaligenes faecalis et rel. 1 2 3 6.1.2 Sparsity The data is sparse: hist(log10(1 + abundances(d)), 100) 6.1.3 Rarity Long tails of rare taxa: library(reshape2) medians &lt;- apply(abundances(d),1,median)/1e3 A &lt;- melt(abundances(d)) A$Var1 &lt;- factor(A$Var1, levels = rev(names(sort(medians)))) p &lt;- ggplot(A, aes(x = Var1, y = value)) + geom_boxplot() + labs(y = &quot;Abundance (reads)&quot;, x = &quot;Taxonomic Group&quot;) + scale_y_log10() print(p) 6.1.4 Overdispersion Variance exceeds the mean: means &lt;- apply(abundances(d),1,mean) variances &lt;- apply(abundances(d),1,var) # Calculate mean and variance over samples for each taxon library(reshape2) library(dplyr) df &lt;- melt(abundances(d)) names(df) &lt;- c(&quot;Taxon&quot;, &quot;Sample&quot;, &quot;Reads&quot;) df &lt;- df %&gt;% group_by(Taxon) %&gt;% summarise(mean = mean(Reads), variance = var(Reads)) # Illustrate overdispersion library(scales) p &lt;- ggplot(df, aes(x = mean, y = variance)) + geom_point() + geom_abline(aes(intercept = 0, slope = 1)) + scale_x_log10(labels = scales::scientific) + scale_y_log10(labels = scales::scientific) + labs(title = &quot;Overdispersion (variance &gt; mean)&quot;) print(p) 6.2 Generalized linear models: a brief overview Let us briefly discuss the ideas underlying generalized linear models. The Generalized linear model (GLM) allows a richer family of probability distributions to describe the data. Intuitively speaking, GLMs allow the modeling of nonlinear, nonsymmetric, and nongaussian associations. GLMs consist of three elements: A probability distribution for the data (from exponential family) A linear predictor targeting the mean, or expectation: \\(Xb\\) A link function g such that \\(E(Y) = \\mu = g^{-1}(Xb)\\). Let us fit Poisson with (natural) log-link just to demonstrate how generalized linear models could be fitted in R. We fit the abundance (read counts) assuming that the data is Poisson distributed, and the logarithm of its mean, or expectation, is obtained with a linear model. For further examples in R, you can also check the statmethods website. # Load again the example data d &lt;- dietswap df &lt;- data.frame(Abundance = abundances(d)[taxa,], Group = meta(d)$nationality) res &lt;- glm(Abundance ~ 1, data = df, family = &quot;poisson&quot;) Investigate the model output: knitr::kable(summary(res)$coefficients, digits = 5) Estimate Std. Error z value Pr(&gt;|z|) (Intercept) 2.09286 0.02357 88.79275 0 Note the link between mean and estimated coefficient (\\(\\mu = e^{Xb}\\)): mean(df$Abundance) ## [1] 8.108108 exp(coef(res)) ## (Intercept) ## 8.108108 6.3 DESeq2: differential abundance testing for sequencing data 6.3.1 Fitting DESeq2 [DESeq2 analysis]((https://genomebiology.biomedcentral.com/articles/10.1186/s13059-014-0550-8) accommodates those particular assumptions about sequencing data. # Start by converting phyloseq object to deseq2 format library(DESeq2) d &lt;- dietswap # Phyloseq data ds2 &lt;- phyloseq_to_deseq2(d, ~ group + nationality) # Run DESeq2 analysis (all taxa at once!) dds &lt;- DESeq(ds2) # Investigate results deseq.results &lt;- as.data.frame(results(dds)) deseq.results$taxon &lt;- rownames(results(dds)) # Sort (arrange) by pvalue and effect size library(knitr) deseq.results &lt;- deseq.results %&gt;% arrange(pvalue, log2FoldChange) # Print the result table # Let us only show significant hits knitr::kable(deseq.results %&gt;% filter(pvalue &lt; 0.05 &amp; log2FoldChange &gt; 1.5), digits = 5) baseMean log2FoldChange lfcSE stat pvalue padj taxon 29.20535 1.91205 0.13432 14.23457 0.00000 0.00000 Clostridium difficile et rel. 51.65152 3.04116 0.28687 10.60107 0.00000 0.00000 Mitsuokella multiacida et rel. 12.39749 1.83825 0.18531 9.91994 0.00000 0.00000 Klebisiella pneumoniae et rel. 44.16494 1.78333 0.23072 7.72937 0.00000 0.00000 Megasphaera elsdenii et rel. 66.93783 1.68345 0.25330 6.64609 0.00000 0.00000 Escherichia coli et rel. 3.63459 1.53142 0.23140 6.61792 0.00000 0.00000 Weissella et rel. 5.74035 3.07334 0.47848 6.42308 0.00000 0.00000 Serratia 0.42171 1.70079 0.47147 3.60743 0.00031 0.00075 Moraxellaceae 6.3.2 Comparison between DESeq2 and standard models For comparison purposes, assess significances and effect sizes based on Wilcoxon test. test.taxa &lt;- taxa(d) pvalue.wilcoxon &lt;- c() foldchange &lt;- c() for (taxa in test.taxa) { # Create a new data frame for each taxonomic group df &lt;- data.frame(Abundance = abundances(d)[taxa,], Log10_Abundance = log10(1 + abundances(d)[taxa,]), Group = meta(d)$nationality) # Calculate pvalue and effect size (difference beween log means) pvalue.wilcoxon[[taxa]] &lt;- wilcox.test(Abundance ~ Group, data = df)$p.value foldchange[[taxa]] &lt;- coef(lm(Log10_Abundance ~ Group, data = df))[[2]] } # Correct p-values for multiple testing pvalue.wilcoxon.adjusted &lt;- p.adjust(pvalue.wilcoxon) par(mfrow = c(1,2)) plot(deseq.results$padj, pvalue.wilcoxon.adjusted, xlab = &quot;DESeq2 adjusted p-value&quot;, ylab = &quot;Wilcoxon adjusted p-value&quot;, main = &quot;P-value comparison&quot;) abline(v = 0.05, h = 0.05, lty = 2) plot(deseq.results$log2FoldChange, foldchange, xlab = &quot;DESeq2&quot;, ylab = &quot;Linear model&quot;, main = &quot;Effect size comparison&quot;) abline(0,1) For systematic comparisons between various methods for differential abundance testing, see this paper. "],
["multivariate-comparisons-of-microbial-community-composition.html", "7 Multivariate comparisons of microbial community composition 7.1 PERMANOVA 7.2 Checking the homogeneity condition", " 7 Multivariate comparisons of microbial community composition The above examples focus on comparison per individual taxonomic group. Often, the groups are correlated and we are interested in comparing the overall community composition. 7.1 PERMANOVA Permutational multivariate analysis of variance further reading. See also statmethods. library(vegan) pseq &lt;- dietswap # Pick relative abundances (compositional) and sample metadata pseq.rel &lt;- microbiome::transform(pseq, &quot;compositional&quot;) otu &lt;- abundances(pseq.rel) meta &lt;- meta(pseq.rel) # samples x species as input library(vegan) permanova &lt;- adonis(t(otu) ~ group, data = meta, permutations=99, method = &quot;bray&quot;) # P-value print(as.data.frame(permanova$aov.tab)[&quot;group&quot;, &quot;Pr(&gt;F)&quot;]) ## [1] 0.04 7.2 Checking the homogeneity condition Type ?betadisper in R console for more information. # Note the assumption of similar multivariate spread among the groups # ie. analogous to variance homogeneity # Here the groups have signif. different spreads and # permanova result may be potentially explained by that. dist &lt;- vegdist(t(otu)) anova(betadisper(dist, meta$group)) ## Analysis of Variance Table ## ## Response: Distances ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Groups 2 0.01252 0.006262 0.6649 0.5154 ## Residuals 219 2.06254 0.009418 permutest(betadisper(dist, meta$group), pairwise = TRUE) ## ## Permutation test for homogeneity of multivariate dispersions ## Permutation: free ## Number of permutations: 999 ## ## Response: Distances ## Df Sum Sq Mean Sq F N.Perm Pr(&gt;F) ## Groups 2 0.01252 0.006262 0.6649 999 0.521 ## Residuals 219 2.06254 0.009418 ## ## Pairwise comparisons: ## (Observed p-value below diagonal, permuted p-value above diagonal) ## DI ED HE ## DI 0.44000 0.694 ## ED 0.44203 0.317 ## HE 0.69469 0.30560 We can also check which taxa contribute most to the community differences. Are these same or different compared to DESeq2? coef &lt;- coefficients(permanova)[&quot;group1&quot;,] top.coef &lt;- coef[rev(order(abs(coef)))[1:20]] par(mar = c(3, 14, 2, 1)) barplot(sort(top.coef), horiz = T, las = 1, main = &quot;Top taxa&quot;) "],
["further-exercises.html", "8 Further exercises 8.1 Compositionality 8.2 Redundancy analysis (RDA)", " 8 Further exercises When done with the differential abundance testing examples, you can investigate the use of the following standard methods for microbiome studies. We are available to discuss and explain the technical aspects in more detail during the class. 8.1 Compositionality Compositionality effect compare the effect of CLR transformation (microbiome::clr) on microbiome analysis results. 1) Compare t-test and/or Wilcoxon test results between data that is transformed with compositional or clr transformation (see the function microbiome::transform); and/or 2) Prepare PCoA with Bray-Curtis distances for compositional data; and PCoA with euclidean distances for CLR-transformed data (microbiome::transform). For examples, see microbiome tutorial. 8.2 Redundancy analysis (RDA) A very good overview of various multivariate methods used in microbial ecology is provided here. Read the Redundancy analysis (and possibly other) section. Next, try to perform simple redundancy analysis in R based on the following examples. Standard RDA for microbiota profiles versus the given (here ‘time’) variable from sample metadata (see also the RDA method in phyloseq::ordinate) x &lt;- transform(dietswap, &quot;compositional&quot;) otu &lt;- abundances(x) metadata &lt;- meta(x) library(vegan) rda.result &lt;- vegan::rda(t(otu) ~ factor(metadata$nationality), na.action = na.fail, scale = TRUE) Visualize the standard RDA output: plot(rda.result, choices = c(1,2), type = &quot;points&quot;, pch = 15, scaling = 3, cex = 0.7, col = metadata$time) points(rda.result, choices = c(1,2), pch = 15, scaling = 3, cex = 0.7, col = metadata$time) pl &lt;- ordihull(rda.result, metadata$nationality, scaling = 3, label = TRUE) Test RDA significance: permutest(rda.result) Include confounding variables: rda.result2 &lt;- vegan::rda(t(otu) ~ metadata$nationality + Condition(metadata$bmi_group + metadata$sex)) "],
["citation-1.html", "9 Citation", " 9 Citation If you found this book useful, please cite: Shetty Sudarshan A, Lahti Leo, Hermes Gerben DA, &amp; Hauke Smidt. (2018, September 27). Microbial bioinformatics introductory course material 2018 (Version 0.01). Zenodo. http://doi.org/10.5281/zenodo.1436630 "]
]
